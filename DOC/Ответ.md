Привет!
0

1. Презентация
Про "несерьезность" - выполняю поставленную задачу Pet-проекта. Задание так и начиналось - со слов "Хороший мальчик" и фото довольного корги - представлено на 2 Слайде.
Кроме того, не обязательно быть строгим, чтобы делать серьезные задачи. Java, Python, linux, hadoop, PostgreSQL, Docker ... имеют мультяшно-игрушечную символику и это не ухудшает их функционал и др. потребительские качества.

1.1 Название поменял на Сайт «Прогноз температуры» или что я узнал за 6 месяцев

1.2 Детализировал описание решаемой задачи на Слайдах 3-5

1.3 Действительно, использовал модель предсказания сделанную на курсе DS в Бауманке. Благодарю за советы по ML, Коллега! Видимо, у меня несколько ревьюеров, т.к. ранее получил комметарий "Понимает, что мы не саентисты и особо не шарим в модельках?" - см. Dobro.jpg
Я понял эту установку и не дорабатывал, не доказывал, не объяснял про ML методы, чтобы никого не смущать. Но на возникшие вопросы отвечу:
-WRF, ECMWF - в бауманке про них не сказали и я не догадался про них посмотреть.
-Пробовал SARIMA - для циклических изенений, получал похожую точносьть на срок до 12ч
-Моя линейная регрессия учитывает нелинейные эффекты, т.к. базируется на полиномиальных (в степенях до кубических) признаках
-Исходно эта модель обучалась в расчете реализации на микрокомпьютере Arduino. Т.е. алгоритм предсказания, с полученными в процессе обучения коэффициентами, реализовывался на C без использования любых библиотек ML. Поэтому простота реализации прогноза этого алгоритма была также критерием его отбора.
-Ответ на не заданный вопрос - зачем четыре объекта предсказания, а не один предсказывающий 4-ре значения !? - тоже объясняется исторически - такой объект и процедуры подготовки данных уже были из прошлой работы. А почему в прошлой работе создавался прогноз одного значения ? - потому что прогноз планировалось выводить на маленький сегментный индикатор из экосистемы Arduino
 Поэтому и здесь 4-ре однотипных ML-модели обучаются предсказывать 1 значение с разной глубиной предсказания будущего - 3, 6, 9, 12ч
 Опять же, напоминаю, защита работы в части DS здесь не планировалось, DS здесь только как демонстрация целостного решения IT-задачи.

Уточнил теги получаемой информации и, в целом, добавил детализации на Слайдах 3-5.
Но и диалог оставил )) Так учат здесь в ЯндексПрактикуме !

1.4 DWH

1.4.1 Таблица уникальных регионов появляется в DDS - показывает, что это я умею делать. Можно и дату еще вынести, но, думаю, не стоит

1.4.2 Очистка перед загрузкой в Stage - конечно, можно. И здесь это было бы хорошо, но нас учили: Stage - данные поступают без обработки, в рамках этой идеологиии так сделал. Очистка дальше

1.4.3 Моё DQ-отбрасывание нечисловых значений Т . Если бы я сделал это в 1.4.2 - здесь бы мне совсем было нечего делать. Больше ничего не нарушается, Airflow не падает и заказчик не жаловался ))

## 2. Описание проекта

2.1 После выполнения 2.2 нет больше opisanie

2.2 Объединил все описания в ReadMe.md, как рекомендуете

2.3 Заменил командами и руководством их выполнения без привязки к ОС

3. Непонятно о чем речь
3.1 В ReadMe указываю что запускать: 3. В UI Airflow http://localhost:3000/airflow/home запустить DAG weather_predict
Борьба с возможной невидимостью DAGf'a описана здесь же в ReadMe (3)

4. ОК

5. DAG
5.1 Благодарю, поправил
5.2 Благодарю,красиво, поправил

6. Ок

## Ответы на Вопросы:

1. Как реализовано регулярное переобучение моделей на новых данных для повышения точности прогнозов?

Не предполагается, повторюсь : ревьюер не рекомендовал углубляться в DS, защита работы в части DS здесь не планировалось, DS здесь только как демонстрация целостного решения IT-задачи.

2. Как реализован мониторинг ETL процессов для отслеживания их выполнения и обнаружения ошибок?

Логи можно видеть через UI Airflow по адресу http://localhost:3000/airflow/home

3. Как ты проводишь проверку результатов обучения моделей с релаьными данными для улучшения результатов?

Возможно, мне стоило больше времени уделить части DS, но нет, этого не делал. Не расчитывал заработать на этом какие-то баллы

4. Настроено ли регулярное резервное копирование данных для обеспечения их сохранности?

Docker-Образы опубликованы в https://hub.docker.com/
Сам проект опубликован в https://github.com/RUS02/PetProjJRG
В случае пересоздания локальных Docker-контейнеров восстановление способности строить прогноз возвращается получении данных о актуальных показаниях температуры от RP5 за 10 часов работы (за 10 часов работы).
Специально резервирование получаемых не производится.
В процессе работы данные старше недели удаляются

5. Как мне запустить твой проект у себя на маке, если первый же бат бежит в диск C?

Описал команды установки и запуска в ReadMe (1,2,3) ОС-независимыми

