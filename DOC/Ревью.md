Привет!

## 1. По поводу презентации:

В качестве шуточной на время работы ок, но я бы конечно советовал переделать в более строгий вид

1.1 Поменять название, потому-что "Docker PostgreS Airflow WEB DE ML DQи с любовью к животным" это просто перечисление технологий с игрой слов )

1.2 Краткое описание тоже лучше указать нормальное, так как ты будешь показывать презентацию другим студентам суть реализации отсюда не уловить

1.3 Дальше не очень понятно, правильно понимаю, что у тебя уже есть модель которая способна предсказывать погоду? Ты реализовал её в рамках проекта "Метеостанция" в бауманке? 

Сразу обозначу, что скептически отношусь к таким историям, так как для предсказания погоды обычно используются сложные методы, такие как численные модели атмосферных процессов (например, WRF, ECMWF), которые учитывают физические законы атмосферы, а выбранные тобой методы, по типу: линейной регрессии, которая подходит для простых линейных зависимостей, но не учитывает нелинейные эффекты и взаимодействия между переменными, ближайшие соседи, которые могут быть эффективны для определенных задач, но их эффективность снижается на больших и многомерных данных и нейросетки которые могут моделировать сложные зависимости, но требуют больших объемов данных и вычислительных ресурсов для обучения, решают задачу ну слишком поверхностно. Не считая того, что на сайте откуда ты берёшь данные есть предсказание на неделю )

На слайде стоит обозначит входные данные, потому что не совем понятно что ты обвёл красными прямоугольниками, для этого надо читать твой монолог ахах

### 1.4 По архитектуре DWH:

1.4.1 Можно добавить дополнительные таблицы для хранения уникальных регионов и других справочных данных. Это позволит избежать дублирования информации и снизить объем хранимых данных

1.4.2 Перед загрузкой в Stage можно добавить этап очистки данных (например, удаление дубликатов, проверка на корректность и т.д.)

1.4.3 Можно добавить шаги валидации данных для проверки их целостности и корректности на всех этапах ETL

## 2. Описание проекта

2.1 Чем нам не угодил description, что пришлось выкручиваться в opisanie?  

2.2 Объедини все документы описания, плана работ и инструкций в один файл, чтобы было удобнее ориентироваться  

2.3 Добавь поддержку для Linux в инструкции установки, так как не все пользователи работают на Windows

## 3. Пайплайн, он же ридмишка почему-то

3.1 По 3 пункту как я должен понять какие части мне комментировать и перезапускать? Почему даг не виден изначально? 

## 4. По структуре таблиц пока нет вопросов


## 5. WORK/doker/weather_yandex_de_ml_server/dag.py

5.1 Используй `with open` для автоматического закрытия файлов.

```py
def ml_weather(pg_schema, pg_table):
    postgres_hook = PostgresHook(postgres_conn_id)
    engine = postgres_hook.get_sqlalchemy_engine()
    # Считываем историю
    df = pd.read_sql_query('SELECT region, dt_max, m0, m1, m2, m3, hh, T_3 as "T-3", T_2 as "T-2", T_1 as "T-1", T0 as "T0" FROM mart.ml_data LIMIT 100;', engine)
    df2 = df.drop(['region', 'dt_max'], axis=1)

    with open('/var/tmp/data_history_x.txt', 'w') as his, open('/var/tmp/data_future_x.txt', 'w') as fut:
        if len(df.index) == 0:
            his.write('Прогноз невозможен\n')
            his.write('Нужно накопить данные\n')
            his.write('за 10 часов\n')
        else:
            # Строим прогноз
            t1 = y_scale.inverse_transform(lr1.predict(PolynomialFeatures(3).fit_transform(X_scale.transform(df2))))[0]
            ...
```

5.2 Загружай модели с помощью цикла

```py
models = {}
for i in range(1, 5):
    models[f'lr{i}'] = pickle.load(open(f'/lessons/dags/ml/lr{i}.sav', 'rb'))
X_scale = pickle.load(open('/lessons/dags/ml/X_scale.sav', 'rb'))
y_scale = pickle.load(open('/lessons/dags/ml/y_scale.sav', 'rb'))
```

## 6. По sql-скриптам пока нет вопросов



## Вопросы:

1. Как реализовано регулярное переобучение моделей на новых данных для повышения точности прогнозов?
2. Как реализован мониторинг ETL процессов для отслеживания их выполнения и обнаружения ошибок?
3. Как ты проводишь проверку результатов обучения моделей с релаьными данными для улучшения результатов?
4. Настроено ли регулярное резервное копирование данных для обеспечения их сохранности?
5. Как мне запустить твой проект у себя на маке, если первый же бат бежит в диск C?







